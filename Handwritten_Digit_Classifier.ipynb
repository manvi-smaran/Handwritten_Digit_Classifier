{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "HSFxbDoIhPHB",
        "tGQmcQP1h09S",
        "Xfmwe_3Rh-JZ",
        "dfNg-M4ziBoa",
        "aFY0evdgp3Q7",
        "cL1hNBd405lN"
      ],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anushka-Verma-CODES/Handwritten_Digit_Classifier/blob/main/Handwritten_Digit_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up PyTorch"
      ],
      "metadata": {
        "id": "J5FRROfthcu4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8Q6ck6ygdPW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms.v2 import ToTensor\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "nKP7PjGrDnoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading and Transforming the Dataset"
      ],
      "metadata": {
        "id": "HSFxbDoIhPHB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        "\n",
        ")\n",
        "test_data=datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "uFs3lEKjxOOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image , label =train_data[0]\n",
        "print(image.shape)\n",
        "print(label)"
      ],
      "metadata": {
        "id": "AtZcRxBIMqAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "figure=plt.figure(figsize=(28,28))\n",
        "cols, rows = 3, 3\n",
        "for i in range(2, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(train_data), size=(1,)).item()\n",
        "    img, label = train_data[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(train_data[label])\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Pc-Zri8pNt4S",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.data.shape\n"
      ],
      "metadata": {
        "id": "e81tZ5cIevPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.data.shape\n"
      ],
      "metadata": {
        "id": "8Y4apUFxfY04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.targets.shape\n"
      ],
      "metadata": {
        "id": "t4oPGX8NfavA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.targets"
      ],
      "metadata": {
        "id": "utOAjDGdfcPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initializing the Model"
      ],
      "metadata": {
        "id": "tGQmcQP1h09S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader=DataLoader(train_data,batch_size=100,shuffle=True)\n",
        "\n",
        "test_dataloader=DataLoader(test_data,batch_size=100,shuffle=True)\n"
      ],
      "metadata": {
        "id": "OoSYqleEW42K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining Model\n",
        "# nn.ReLU & nn.Tanh()\n",
        "model = nn.Sequential(\n",
        "      nn.Flatten(),\n",
        "      nn.Linear(28*28,128),\n",
        "      nn.Tanh(),\n",
        "      nn.Linear(128,10)\n",
        "      ).to(device)\n",
        "\n",
        "# model = nn.Sequential(\n",
        "#       nn.Flatten(),\n",
        "#       nn.Linear(28*28,256),\n",
        "#       nn.Tanh(),\n",
        "#       nn.Linear(256,128),\n",
        "#       nn.Tanh(),\n",
        "#       nn.Linear(128,10)\n",
        "#       ).to(device)\n",
        "\n",
        "# model = nn.Sequential(\n",
        "#       nn.Flatten(),\n",
        "#       nn.Linear(28*28,256),\n",
        "#       nn.Tanh(),\n",
        "#       nn.Linear(256,128),\n",
        "#       nn.Tanh(),\n",
        "#       nn.Linear(128,64),\n",
        "#       nn.Tanh(),\n",
        "#       nn.Linear(64, 10)\n",
        "#       ).to(device)"
      ],
      "metadata": {
        "id": "nNQXggkpgjt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining Optimizer\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # Adam\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9) # SGD"
      ],
      "metadata": {
        "id": "hRi7Uyf7rnZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func=nn.CrossEntropyLoss() # Defining Loss Function"
      ],
      "metadata": {
        "id": "oviLYozOsd_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10 # Defining epochs (5, 10, 20)\n",
        "for batch_x, batch_y in train_dataloader:\n",
        "  print(batch_x.shape)\n",
        "  print(batch_y.shape)\n",
        "  break"
      ],
      "metadata": {
        "id": "SpGxAYNVsvLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the Model"
      ],
      "metadata": {
        "id": "Xfmwe_3Rh-JZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  model.train() #setting the train mode\n",
        "  total_loss=0\n",
        "  for batch_x,batch_y in train_dataloader:\n",
        "    y_pred=model(batch_x) #forward pass\n",
        "    loss=loss_func(y_pred,batch_y)#calclating the loss\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()#backpropagation on loss w.r.t parameter of the model\n",
        "    optimizer.step()\n",
        "    total_loss += loss.item()\n",
        "  print(f\"Epoch {epoch+1}, Avg Loss: {total_loss / len(train_dataloader):.4f}\")"
      ],
      "metadata": {
        "id": "Ad3ZY4bF2tJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing the Model"
      ],
      "metadata": {
        "id": "dfNg-M4ziBoa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()  # Set model to evaluation mode\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "test_loss = 0\n",
        "\n",
        "with torch.inference_mode():  # or use torch.no_grad()\n",
        "    for batch_x, batch_y in test_dataloader:\n",
        "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "\n",
        "        y_pred_new = model(batch_x)                # forward pass\n",
        "        test_loss += loss_func(y_pred_new, batch_y)  # accumulate loss\n",
        "\n",
        "        predicted = torch.argmax(y_pred_new, dim=1)  # get predicted class\n",
        "        correct += (predicted == batch_y).sum()\n",
        "        total += batch_y.size(0)\n",
        "\n",
        "avg_loss = test_loss / len(test_dataloader)\n",
        "accuracy = correct / total * 100\n",
        "\n",
        "print(f\"Test Loss: {avg_loss:.4f}, Test Accuracy: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "id": "5nSyzhwvEYiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observation Table\n",
        "| **Config** | **Epochs** |              **Layers**             |              **Neurons**             | **Activation** | **Optimizer** | **Test Accuracy (%)** |\n",
        "|:----------:|:----------:|:-----------------------------------:|:------------------------------------:|:--------------:|:-------------:|:---------------------:|\n",
        "|     #1     |      5     |           1 (Output Layer)          |                  128                 |      relu      |      adam     |         97.33         |\n",
        "|     #2     |      5     |  2 (1 Output Layer; 1 Hidden Layer) |      256 (L1 -> 256; L2 -> 128)      |      relu      |      adam     |         97.84         |\n",
        "|     #3     |      5     | 3 (1 Output Layer; 2 Hidden Layers) | 256 (L1 -> 256; L2 -> 128; L3 -> 64) |      relu      |      adam     |         97.60         |\n",
        "|     #4     |      5     |           1 (Output Layer)          |                  128                 |      tanh      |      sgd      |         95.10         |\n",
        "|     #5     |      5     |  2 (1 Output Layer; 1 Hidden Layer) |      256 (L1 -> 256; L2 -> 128)      |      tanh      |      sgd      |         95.51         |\n",
        "|     #6     |      5     | 3 (1 Output Layer; 2 Hidden Layers) | 256 (L1 -> 256; L2 -> 128; L3 -> 64) |      tanh      |      sgd      |         95.79         |\n",
        "|     #7     |     10     |           1 (Output Layer)          |                  128                 |      relu      |      adam     |         97.32         |\n",
        "|     #8     |     10     |  2 (1 Output Layer; 1 Hidden Layer) |      256 (L1 -> 256; L2 -> 128)      |      relu      |      adam     |         97.92         |\n",
        "|     #9     |     10     | 3 (1 Output Layer; 2 Hidden Layers) | 256 (L1 -> 256; L2 -> 128; L3 -> 64) |      relu      |      adam     |         97.98         |\n",
        "|     #10    |     10     |           1 (Output Layer)          |                  128                 |      tanh      |      sgd      |         96.63         |\n",
        "|     #11    |     10     |  2 (1 Output Layer; 1 Hidden Layer) |      256 (L1 -> 256; L2 -> 128)      |      tanh      |      sgd      |         96.94         |\n",
        "|     #12    |     10     | 3 (1 Output Layer; 2 Hidden Layers) | 256 (L1 -> 256; L2 -> 128; L3 -> 64) |      tanh      |      sgd      |         97.34         |\n",
        "|     #13    |     20     |           1 (Output Layer)          |                  128                 |      relu      |      adam     |         97.95         |\n",
        "|     #14    |     20     |  2 (1 Output Layer; 1 Hidden Layer) |      256 (L1 -> 256; L2 -> 128)      |      relu      |      adam     |         98.11         |\n",
        "|     #15    |     20     | 3 (1 Output Layer; 2 Hidden Layers) | 256 (L1 -> 256; L2 -> 128; L3 -> 64) |      relu      |      adam     |         98.00         |\n",
        "|     #16    |     20     |           1 (Output Layer)          |                  128                 |      tanh      |      sgd      |         97.74         |\n",
        "|     #17    |     20     |  2 (1 Output Layer; 1 Hidden Layer) |      256 (L1 -> 256; L2 -> 128)      |      tanh      |      sgd      |         98.03         |\n",
        "|     #18    |     20     | 3 (1 Output Layer; 2 Hidden Layers) | 256 (L1 -> 256; L2 -> 128; L3 -> 64) |      tanh      |      sgd      |         97.99         |"
      ],
      "metadata": {
        "id": "j9meDfnkiF79"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "RQ_9B1B-kc6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import pandas as pd\n",
        "import itertools\n",
        "import os"
      ],
      "metadata": {
        "id": "K5fzEtkdkkJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset and Transforms"
      ],
      "metadata": {
        "id": "Rz4Iotvnksea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.0,), (1.0,))\n",
        "])\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1000)"
      ],
      "metadata": {
        "id": "_REEUJVAkynU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Builder Function"
      ],
      "metadata": {
        "id": "c98DQmsZk0dF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(hidden_layers, neurons, activation_fn):\n",
        "    layers = [nn.Flatten()]\n",
        "    in_features = 28 * 28\n",
        "\n",
        "    for _ in range(hidden_layers):\n",
        "        layers.append(nn.Linear(in_features, neurons))\n",
        "        layers.append(activation_fn())\n",
        "        in_features = neurons\n",
        "\n",
        "    layers.append(nn.Linear(in_features, 10))\n",
        "    return nn.Sequential(*layers)"
      ],
      "metadata": {
        "id": "ytE7a3m8k4C8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation Function"
      ],
      "metadata": {
        "id": "vzl8matpk8t5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in test_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            pred = model(x).argmax(dim=1)\n",
        "            correct += (pred == y).sum().item()\n",
        "    return correct / len(test_loader.dataset)"
      ],
      "metadata": {
        "id": "yfKDB7eLlBln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameter Grid\n",
        "epochs_list = [5, 10, 20]\n",
        "hidden_layers_list = [1, 2]\n",
        "neurons_list = [64, 128, 256]\n",
        "activations = {'ReLU': nn.ReLU, 'Tanh': nn.Tanh}\n",
        "optimizers = {'Adam': optim.Adam, 'SGD': optim.SGD}"
      ],
      "metadata": {
        "id": "FqRT5_E2lK5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Device and Logging\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "results = []\n",
        "best_accuracy = 0.0\n",
        "best_model_state = None"
      ],
      "metadata": {
        "id": "M5-IlSlQlRF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loop over combinations\n",
        "for epochs, hidden_layers, neurons, (act_name, act_fn), (opt_name, opt_cls) in itertools.product(\n",
        "    epochs_list, hidden_layers_list, neurons_list, activations.items(), optimizers.items()\n",
        "):\n",
        "    print(f\"Training: Epochs={epochs}, Layers={hidden_layers}, Neurons={neurons}, Activation={act_name}, Optimizer={opt_name}\")\n",
        "\n",
        "    model = build_model(hidden_layers, neurons, act_fn).to(device)\n",
        "    optimizer = opt_cls(model.parameters())\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for x, y in train_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            y_pred = model(x)\n",
        "            loss = loss_fn(y_pred, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Evaluation\n",
        "    accuracy = evaluate(model, test_loader)\n",
        "    results.append({\n",
        "        'epochs': epochs,\n",
        "        'hidden_layers': hidden_layers,\n",
        "        'neurons': neurons,\n",
        "        'activation': act_name,\n",
        "        'optimizer': opt_name,\n",
        "        'test_accuracy': accuracy\n",
        "    })\n",
        "\n",
        "    # Save best model\n",
        "    if accuracy > best_accuracy:\n",
        "        best_accuracy = accuracy\n",
        "        best_model_state = model.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbqp8e20gebU",
        "outputId": "d1388b28-6b9e-495b-9a4f-08210d35311c"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training: Epochs=5, Layers=1, Neurons=64, Activation=ReLU, Optimizer=Adam\n",
            "Training: Epochs=5, Layers=1, Neurons=64, Activation=ReLU, Optimizer=SGD\n",
            "Training: Epochs=5, Layers=1, Neurons=64, Activation=Tanh, Optimizer=Adam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save results\n"
      ],
      "metadata": {
        "id": "aFY0evdgp3Q7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(results)\n",
        "df.to_csv(\"hyperparameter_results.csv\", index=False)\n",
        "torch.save(best_model_state, \"best_model_state.pth\")\n",
        "\n",
        "print(\"‚úÖ Hyperparameter search complete.\")\n",
        "print(f\"üèÜ Best test accuracy: {best_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "GJx9jc6Qpse1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis & Visualization"
      ],
      "metadata": {
        "id": "cL1hNBd405lN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "df = pd.read_csv(\"hyperparameter_results.csv\")"
      ],
      "metadata": {
        "id": "dMwRZZN20Bnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sort by accuracy to find best\n",
        "top_5 = df.sort_values(by=\"test_accuracy\", ascending=False).head(5)\n",
        "print(\"üèÖ Top 5 Models by Test Accuracy:\")\n",
        "print(top_5)\n",
        "\n",
        "sns.set(style=\"whitegrid\")"
      ],
      "metadata": {
        "id": "SJVnLScS0JlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy vs Epochs\n"
      ],
      "metadata": {
        "id": "yJergQl20YiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "sns.lineplot(data=df, x=\"epochs\", y=\"test_accuracy\", marker='o')\n",
        "plt.title(\"Test Accuracy vs Epochs\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Test Accuracy\")\n",
        "plt.savefig(\"accuracy_vs_epochs.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jHVc8lqe0UJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Activation Function Comparison"
      ],
      "metadata": {
        "id": "LmhZufkU0gS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "sns.boxplot(data=df, x=\"activation\", y=\"test_accuracy\")\n",
        "plt.title(\"Activation Function vs Test Accuracy\")\n",
        "plt.savefig(\"activation_comparison.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yz9LfD6v0bjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimizer Comparison"
      ],
      "metadata": {
        "id": "bM6qyE8M0n8I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "sns.boxplot(data=df, x=\"optimizer\", y=\"test_accuracy\")\n",
        "plt.title(\"Optimizer vs Test Accuracy\")\n",
        "plt.savefig(\"optimizer_comparison.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qbayhI2_0j1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Heatmap of Neurons vs Accuracy (for each hidden layer count)"
      ],
      "metadata": {
        "id": "b3Kwe8aO0rZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for layers in df['hidden_layers'].unique():\n",
        "    subset = df[df['hidden_layers'] == layers].pivot_table(\n",
        "        index=\"neurons\", columns=\"epochs\", values=\"test_accuracy\", aggfunc='mean'\n",
        "    )\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    sns.heatmap(subset, annot=True, fmt=\".4f\", cmap=\"YlGnBu\")\n",
        "    plt.title(f\"Heatmap - Neurons vs Epochs (Hidden Layers={layers})\")\n",
        "    plt.savefig(f\"heatmap_neurons_epochs_layers_{layers}.png\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "0TgfYxBT0xCq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}